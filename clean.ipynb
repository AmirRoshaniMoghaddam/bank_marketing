{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0555d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#!pip install imblearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d692c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "#!pip install -U scikit-learn\n",
    "\n",
    "\n",
    "#### Ask why it is giving an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56a037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\brzro\\concordia_bootcamp\\bank_marketing\\data\\bank-additional\\bank-additional-full.csv\", sep = ';')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83f46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0e59ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     36537\n",
       "yes     4639\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227885ae",
   "metadata": {},
   "source": [
    "### Train_Test Split & Stratifying:\n",
    "\n",
    "since the number of positive answers is importatn in this analysis, we should have similar percentage of positives in either of the test and train sets as the percentage of positives in the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2118f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42 )\n",
    "for train_index, test_index in split.split(df, df['y']):\n",
    "    strat_train = df.loc[train_index]\n",
    "    strat_test = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f19096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perdentage of yes in the original dataset 11.266\n",
      "perdentage of yes in strat_train 11.266\n",
      "perdentage of yes in strat_test 11.268\n"
     ]
    }
   ],
   "source": [
    "print('perdentage of yes in the original dataset', \n",
    "      round(len(df[df['y']=='yes'])*100/len(df), 3))\n",
    "\n",
    "print('perdentage of yes in strat_train', \n",
    "      round(len(strat_train[strat_train['y']=='yes'])*100/len(strat_train),3))\n",
    "\n",
    "print('perdentage of yes in strat_test', \n",
    "      round(len(strat_test[strat_test['y']=='yes'])*100/len(strat_test),3))\n",
    "\n",
    "\n",
    "# it is stratified successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a962cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_X = strat_train.drop('y', axis = 1)\n",
    "strat_train_y = strat_train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26db800",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(strat_train_X, strat_train_y, test_size=0.2, random_state=42, stratify = strat_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "520de050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of yes and no in the train set\n",
      " no     88.733303\n",
      "yes    11.266697\n",
      "Name: y, dtype: float64\n",
      "percentage of yes and no in the test set\n",
      " no     0.887371\n",
      "yes    0.112629\n",
      "Name: y, dtype: float64\n",
      "number of yes and no in the train set\n",
      " no     23383\n",
      "yes     2969\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking the stratification is done correctly\n",
    "\n",
    "print('percentage of yes and no in the train set\\n', \n",
    "      100*y_train.value_counts()/len(y_train))\n",
    "print('percentage of yes and no in the test set\\n',\n",
    "      y_test.value_counts()/len(y_test))\n",
    "print('number of yes and no in the train set\\n', \n",
    "      y_train.value_counts()) # data is highly imbalanced, tuning is required\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767dde64",
   "metadata": {},
   "source": [
    "### How to deal with the imbalanced data set?\n",
    "\n",
    "Most Machine Learning models work well when a classification problem is relatively balanced. Since the data is highly imbalanced, we should use downsampling, upsampling, adding class weights or provide a reason why we believe we shoud keep the data as it is.\n",
    "\n",
    "For this project, I use undersampling and adding class weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324597fc",
   "metadata": {},
   "source": [
    "### Performance measurement for an imbalanced data set:\n",
    "\n",
    "1- Balanced Accuracy\n",
    "\n",
    "2- AUC\n",
    "\n",
    "3- F1 score which will consider both precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1c240",
   "metadata": {},
   "source": [
    "### Undersampling dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d6bf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = strat_train[strat_train['y']=='yes'] # the train that y == yes\n",
    "#yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "031fe611",
   "metadata": {},
   "outputs": [],
   "source": [
    "no = strat_train[strat_train['y']=='no'] # the train that y== no\n",
    "#no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8251e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sample = no.sample(random_state = 42, frac = 0.30) # undersampling the No s\n",
    "#no_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8f1eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "under = pd.concat([yes, no_sample])  # create a new dataset and shuffle it\n",
    "under = shuffle(under, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f778d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_X = under.drop('y', axis = 1) # the undersampled X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c128531",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_y = under.y # the undersampled y\n",
    "#under_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5205182",
   "metadata": {},
   "source": [
    "Now the sample is ready for further analysis. We have created an undersampled dataset, and also we have the original dataset (we will use both with and without class weight). Therefore, we can compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae8f2b",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "The main purpose of this part is to create dummies for categorical variables, and deal with some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227acff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### age:\n",
    "# under_X.loc[under_X['age']> 65, 'age'] = 65 \n",
    "\n",
    "# ### campaign:\n",
    "# under_X.loc[under_X['campaign']> 9, 'campaign'] = 9### the max is 56 and it is not a reasonable number so we jsut put a cap on the max \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47c9e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#under_X = under_X.drop('index', axis = 1)\n",
    "under_X = under_X.drop('pdays', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddc07d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['age', 'duration' , 'campaign', 'previous', 'emp.var.rate',\n",
    "            'cons.price.idx','cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "categoricals = ['job', 'marital', 'education', 'default', 'housing',\n",
    "                    'loan', 'contact', 'month', 'day_of_week', 'poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7284582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dummies:\n",
    "\n",
    "under_X_d = pd.get_dummies(under_X, columns = categoricals, drop_first=True)\n",
    "#under_X_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd0f3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_y_new = np.where(under_y == 'yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2315553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#under_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9f7887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#under_y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d46c8",
   "metadata": {},
   "source": [
    "now the under_sampled data is ready for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66ca25",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcc9fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "under_X_scaled = scalar.fit_transform(under_X_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a54b6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=42, max_iter=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "399959c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000000, random_state=42)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(under_X_scaled, under_y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "855c3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = LR.predict(under_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d674d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91      8769\n",
      "           1       0.80      0.74      0.77      3711\n",
      "\n",
      "    accuracy                           0.87     12480\n",
      "   macro avg       0.85      0.83      0.84     12480\n",
      "weighted avg       0.87      0.87      0.87     12480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(under_y_new, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed257b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
